---
title: "Claude misses nuance"
---

## Add contrasting conceptual distinction to your instructions

Sometimes it's helpful to create and explain binary or n-ary concepts and contrast them with one another in order to get the kind of response you want from Claude. This can be done for fairly nuanced concepts, so if there’s a specific kind of response you want, it can be useful to think of what distinguishes it from other kinds of responses, giving it a name, and then specifically requesting that kind of response. 

Example: 

| Role | Prompt                                                                                                                                                                                                                                                                                                         |
| ---- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| User | We can divide responses into polite and impolite response. Polite responses are those that {{polite response features}}. Impolite responses are those that {{impolite response features}}. It’s good to give polite responses in {{circumstances}} but less important in {{circumstances}}. Do you understand? |

Then have the assistant explain back the conceptual distinction and when one kind of response is useful. 

Given this, you can ask the model to do things like classify responses into one of the multiple conceptual buckets (e.g., polite or impolite), or to give a response of one type and not the other.

---

## List examples of incorrect responses and describe bad examples

In your prompt, try listing examples of incorrect responses, especially kinds of incorrect responses you see that the model often gives.

You can list these in your instructions _(”Here is an incorrect example: “)_, or as part of a few-shot conversation prompt:

| Role      | Prompt                                                                                                                                                             |
| --------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| User      | \[description of rules\]\[task description\]First, to make sure you understand the task, please list some answers that would violate the restrictions I described. |
| Assistant | \[response\]                                                                                                                                                       |
| User      | Yes, exactly. Here is another task.\[task description\]Please now list some answers that _do not violate_ the restrictions I described.                            |
| Assistant | \[response\]                                                                                                                                                       |
| User      | Yes, exactly. Here is another task.\[task description\]Please now list some answers that _do not violate_ the restrictions I described.                            |

> ## 💡
> 
> Positive vs. Negative Examples
> 
> In general, it is better to give Claude examples of what it should do over examples of what it shouldn't do. Claude is better at following instructions via pattern matching to examples given. If your prompt requires that you give Claude examples of what not to do, be sure to also include examples of what Claude ought to do instead as well.